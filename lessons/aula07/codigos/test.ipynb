{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0I4pgzLVtBTP"
   },
   "source": [
    "# 1.0 An end-to-end classification problem (Testing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh34gim6KPtT"
   },
   "source": [
    "## 1.1 Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE8OJoDZ5AFK"
   },
   "source": [
    "We'll be looking at individual income in the United States. The **data** is from the **1994 census**, and contains information on an individual's **marital status**, **age**, **type of work**, and more. The **target column**, or what we want to predict, is whether individuals make less than or equal to 50k a year, or more than **50k a year**.\n",
    "\n",
    "You can download the data from the [University of California, Irvine's website](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "Let's take the following steps:\n",
    "\n",
    "1. ETL (done)\n",
    "2. Data Checks (done)\n",
    "3. Data Segregation (done)\n",
    "4. Training (done)\n",
    "5. Test\n",
    "\n",
    "<center><img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1hlrTKNJOg6Svs7V6ihiypsy21UVBTJWv\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UpxKxU1Ej7f"
   },
   "source": [
    "## 1.2 Install, load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t82KewAPWCYe"
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NreRnbvI8lL5"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZXcN54GkP25"
   },
   "outputs": [],
   "source": [
    "# Login to Weights & Biases\n",
    "!wandb login --relogin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ueX2KClcICb"
   },
   "source": [
    "## 1.3 Test evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU-ssUv-gx8K"
   },
   "source": [
    "### 1.3.1 Definition of the base classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeqPYBtbg7DF"
   },
   "source": [
    "This is necessary in order to ```joblib.load()```see the previous definitions used in the Train Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQ4naPLtgVAm"
   },
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    # Class Constructor\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    # Return self nothing else to do here\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    # Method that describes what this custom transformer need to do\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.feature_names]\n",
    "\n",
    "# Handling categorical features\n",
    "class CategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Class constructor method that takes one boolean as its argument\n",
    "    def __init__(self, new_features=True, colnames=None):\n",
    "        self.new_features = new_features\n",
    "        self.colnames = colnames\n",
    "\n",
    "    # Return self nothing else to do here\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def get_feature_names_out(self):\n",
    "        return self.colnames.tolist()\n",
    "\n",
    "    # Transformer method we wrote for this transformer\n",
    "    def transform(self, X, y=None):\n",
    "        df = pd.DataFrame(X, columns=self.colnames)\n",
    "\n",
    "        # Remove white space in categorical features\n",
    "        df = df.apply(lambda row: row.str.strip())\n",
    "\n",
    "        # customize feature?\n",
    "        # How can I identify what needs to be modified? EDA!!!!\n",
    "        if self.new_features:\n",
    "\n",
    "            # minimize the cardinality of native_country feature\n",
    "            # check cardinality using df.native_country.unique()\n",
    "            df.loc[df['native_country'] != 'United-States','native_country'] = 'non_usa'\n",
    "\n",
    "            # replace ? with Unknown\n",
    "            edit_cols = ['native_country', 'occupation', 'workclass']\n",
    "            for col in edit_cols:\n",
    "                df.loc[df[col] == '?', col] = 'unknown'\n",
    "\n",
    "            # decrease the cardinality of education feature\n",
    "            hs_grad = ['HS-grad', '11th', '10th', '9th', '12th']\n",
    "            elementary = ['1st-4th', '5th-6th', '7th-8th']\n",
    "            # replace\n",
    "            df['education'].replace(to_replace=hs_grad,value='HS-grad',inplace=True)\n",
    "            df['education'].replace(to_replace=elementary,value='elementary_school',inplace=True)\n",
    "\n",
    "            # adjust marital_status feature\n",
    "            married = ['Married-spouse-absent','Married-civ-spouse','Married-AF-spouse']\n",
    "            separated = ['Separated', 'Divorced']\n",
    "\n",
    "            # replace\n",
    "            df['marital_status'].replace(to_replace=married, value='Married', inplace=True)\n",
    "            df['marital_status'].replace(to_replace=separated, value='Separated', inplace=True)\n",
    "\n",
    "            # adjust workclass feature\n",
    "            self_employed = ['Self-emp-not-inc', 'Self-emp-inc']\n",
    "            govt_employees = ['Local-gov', 'State-gov', 'Federal-gov']\n",
    "\n",
    "            # replace elements in list.\n",
    "            df['workclass'].replace(to_replace=self_employed,value='Self_employed',inplace=True)\n",
    "            df['workclass'].replace(to_replace=govt_employees,value='Govt_employees',inplace=True)\n",
    "\n",
    "        # update column names\n",
    "        self.colnames = df.columns\n",
    "\n",
    "        return df\n",
    "        \n",
    "# transform numerical features\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Class constructor method that takes a model parameter as its argument\n",
    "    # model 0: minmax\n",
    "    # model 1: standard\n",
    "    # model 2: without scaler\n",
    "    def __init__(self, model=0, colnames=None):\n",
    "        self.model = model\n",
    "        self.colnames = colnames\n",
    "        self.scaler = None\n",
    "\n",
    "    # Fit is used only to learn statistical about Scalers\n",
    "    def fit(self, X, y=None):\n",
    "        df = pd.DataFrame(X, columns=self.colnames)\n",
    "        # minmax\n",
    "        if self.model == 0:\n",
    "            self.scaler = MinMaxScaler()\n",
    "            self.scaler.fit(df)\n",
    "        # standard scaler\n",
    "        elif self.model == 1:\n",
    "            self.scaler = StandardScaler()\n",
    "            self.scaler.fit(df)\n",
    "        return self\n",
    "\n",
    "    # return columns names after transformation\n",
    "    def get_feature_names_out(self):\n",
    "        return self.colnames\n",
    "\n",
    "    # Transformer method we wrote for this transformer\n",
    "    # Use fitted scalers\n",
    "    def transform(self, X, y=None):\n",
    "        df = pd.DataFrame(X, columns=self.colnames)\n",
    "\n",
    "        # update columns name\n",
    "        self.colnames = df.columns.tolist()\n",
    "\n",
    "        # minmax\n",
    "        if self.model == 0:\n",
    "            # transform data\n",
    "            df = self.scaler.transform(df)\n",
    "        elif self.model == 1:\n",
    "            # transform data\n",
    "            df = self.scaler.transform(df)\n",
    "        else:\n",
    "            df = df.values\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N4nmtemhLLZ"
   },
   "source": [
    "### 1.3.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-2z7Fq7cdbX"
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "# name of the artifact related to test dataset\n",
    "artifact_test_name = \"decision_tree/test.csv:latest\"\n",
    "\n",
    "# name of the model artifact\n",
    "artifact_model_name = \"decision_tree/model_export:latest\"\n",
    "\n",
    "# name of the target encoder artifact\n",
    "artifact_encoder_name = \"decision_tree/target_encoder:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOh7odFBdO88"
   },
   "outputs": [],
   "source": [
    "# configure logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s %(message)s\",\n",
    "                    datefmt='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "# reference for a logging obj\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O177vAixdW9i"
   },
   "outputs": [],
   "source": [
    "# initiate the wandb project\n",
    "run = wandb.init(project=\"decision_tree\",job_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siFQuqmvdiRO"
   },
   "outputs": [],
   "source": [
    "logger.info(\"Downloading and reading test artifact\")\n",
    "test_data_path = run.use_artifact(artifact_test_name).file()\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# Extract the target from the features\n",
    "logger.info(\"Extracting target from dataframe\")\n",
    "x_test = df_test.copy()\n",
    "y_test = x_test.pop(\"high_income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdXTWnBfdwbE"
   },
   "outputs": [],
   "source": [
    "# Takes a look at test set\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irBhj9UXdybG"
   },
   "outputs": [],
   "source": [
    "# Take a look at the target variable\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwIVe_-GeBFz"
   },
   "outputs": [],
   "source": [
    "# Extract the encoding of the target variable\n",
    "logger.info(\"Extracting the encoding of the target variable\")\n",
    "encoder_export_path = run.use_artifact(artifact_encoder_name).file()\n",
    "le = joblib.load(encoder_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtdxHiF7e8oJ"
   },
   "outputs": [],
   "source": [
    "# transform y_train\n",
    "y_test = le.transform(y_test)\n",
    "logger.info(\"Classes [0, 1]: {}\".format(le.inverse_transform([0, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRJ_dDWNfD0Z"
   },
   "outputs": [],
   "source": [
    "# target variable after the encoding\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hubXniw5fGc_"
   },
   "outputs": [],
   "source": [
    "# Download inference artifact\n",
    "logger.info(\"Downloading and load the exported model\")\n",
    "model_export_path = run.use_artifact(artifact_model_name).file()\n",
    "pipe = joblib.load(model_export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AmX-6-Sf0v0"
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "logger.info(\"Infering\")\n",
    "predict = pipe.predict(x_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "logger.info(\"Test Evaluation metrics\")\n",
    "fbeta = fbeta_score(y_test, predict, beta=1, zero_division=1)\n",
    "precision = precision_score(y_test, predict, zero_division=1)\n",
    "recall = recall_score(y_test, predict, zero_division=1)\n",
    "acc = accuracy_score(y_test, predict)\n",
    "\n",
    "logger.info(\"Test Accuracy: {}\".format(acc))\n",
    "logger.info(\"Test Precision: {}\".format(precision))\n",
    "logger.info(\"Test Recall: {}\".format(recall))\n",
    "logger.info(\"Test F1: {}\".format(fbeta))\n",
    "\n",
    "run.summary[\"Acc\"] = acc\n",
    "run.summary[\"Precision\"] = precision\n",
    "run.summary[\"Recall\"] = recall\n",
    "run.summary[\"F1\"] = fbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRdA8Djahueu"
   },
   "outputs": [],
   "source": [
    "# Compare the accuracy, precision, recall with previous ones\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuM6sg3wh6k_"
   },
   "outputs": [],
   "source": [
    "fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n",
    "ConfusionMatrixDisplay(confusion_matrix(predict,y_test,labels=[1,0]),\n",
    "                       display_labels=[\">50k\",\"<=50k\"]).plot(values_format=\".0f\",ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"True Label\")\n",
    "ax.set_ylabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXis7klgiEWG"
   },
   "outputs": [],
   "source": [
    "# Uploading figures\n",
    "logger.info(\"Uploading figures\")\n",
    "run.log(\n",
    "    {\n",
    "        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n",
    "        # \"other_figure\": wandb.Image(other_fig)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFC4iWBmiTKe"
   },
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ln5TlQjURzBp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
